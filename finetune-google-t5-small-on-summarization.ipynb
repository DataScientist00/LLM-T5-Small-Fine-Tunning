{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://i.postimg.cc/rm2vJ3FD/Screenshot-2025-06-25-212115.png)","metadata":{}},{"cell_type":"markdown","source":"# Youtube Video Link -->> https://youtu.be/Dous6pBrYbc","metadata":{}},{"cell_type":"code","source":"# Install required libraries\n\n# !pip install -q datasets transformers accelerate transformers[sentencepiece] sacrebleu rouge_score py7zr\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T09:18:20.946257Z","iopub.execute_input":"2025-06-25T09:18:20.946827Z","iopub.status.idle":"2025-06-25T09:19:36.560413Z","shell.execute_reply.started":"2025-06-25T09:18:20.946805Z","shell.execute_reply":"2025-06-25T09:19:36.559689Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 📦 1. Import Libraries & Suppress Warnings","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset  # Load dataset\nimport torch  # PyTorch tensors & GPU\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM  # Automatically picks the right tokenizer & model\nfrom transformers import DataCollatorForSeq2Seq  # Dynamic padding and batching\nfrom transformers import TrainingArguments, Trainer  # Training setup & loop\nfrom transformers import pipeline  # High-level API for easy inference\nimport warnings  # Handle warnings\nwarnings.filterwarnings(\"ignore\")  # Suppress warnings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:20:04.138805Z","iopub.execute_input":"2025-06-25T10:20:04.139117Z","iopub.status.idle":"2025-06-25T10:20:04.143519Z","shell.execute_reply.started":"2025-06-25T10:20:04.139096Z","shell.execute_reply":"2025-06-25T10:20:04.142899Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# 🤖 2. Load Model & Tokenizer","metadata":{}},{"cell_type":"code","source":"\nmodel_checkpoint = \"t5-small\"  # ✅ You can also use \"google/flan-t5-base\", \"facebook/bart-base\", etc.\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(\"cuda\")\n\n# ===== Popular Summarization Models Sorted by Parameters (Smallest → Largest) =====\n\n# \"t5-small\" (60M params) (add \"summarize:\" before each dialogue) — ✅ fastest to train\n# \"google/flan-t5-small\" (80M params) (add \"summarize:\" before each dialogue) — ⚡ fast, generalizes well\n# \"facebook/bart-base\" (139M params) (no \"summarize:\" needed) — 📈 solid performance\n# \"sshleifer/distilbart-cnn-12-6\" (139M params) (no \"summarize:\" needed) — 🔁 faster BART variant\n# \"t5-base\" (220M params) (add \"summarize:\" before each dialogue) — 🧠 good quality, moderate speed\n# \"google/flan-t5-base\" (250M params) (add \"summarize:\" before each dialogue) — 🚀 better than t5-base in low-data settings\n# \"facebook/bart-large\" (406M params) (no \"summarize:\" needed) — 💎 strong quality, slower\n# \"google/pegasus-cnn_dailymail\" (568M params) (no \"summarize:\" needed) — 🦾 very good for abstractive summarization\n# \"t5-large\" (770M params) (add \"summarize:\" before each dialogue) — 🐢 slow, high-quality\n\n# ===== Dataset Prep Summary =====\n# T5 / FLAN-T5 → add \"summarize: \" before each dialogue\n# BART / DistilBART / Pegasus → use raw dialogue (no prefix)\n# All → tokenize dialogue (max_length=1024), tokenize summary (max_length=128)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:20:05.310626Z","iopub.execute_input":"2025-06-25T10:20:05.310885Z","iopub.status.idle":"2025-06-25T10:20:06.199014Z","shell.execute_reply.started":"2025-06-25T10:20:05.310867Z","shell.execute_reply":"2025-06-25T10:20:06.198473Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# 📚 3. Load SAMSum Dataset\n","metadata":{}},{"cell_type":"code","source":"# Load SAMSum Dataset\ndataset = load_dataset(\"knkarthick/samsum\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:20:08.695631Z","iopub.execute_input":"2025-06-25T10:20:08.696215Z","iopub.status.idle":"2025-06-25T10:20:10.891599Z","shell.execute_reply.started":"2025-06-25T10:20:08.696189Z","shell.execute_reply":"2025-06-25T10:20:10.891043Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# ✂️ 4. Tokenize the Dataset","metadata":{}},{"cell_type":"code","source":"# Tokenize the Dataset\ndef tokenize_content(data):\n    dialogues = data[\"dialogue\"]\n    summaries = data[\"summary\"]\n\n    inputs = [\"summarize: \" + d if d else \"summarize: \" for d in dialogues]\n    targets = [s if s else \"\" for s in summaries]\n\n    input_encoding = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n    with tokenizer.as_target_tokenizer():\n        target_encoding = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n\n    return {\n        \"input_ids\": input_encoding[\"input_ids\"],\n        \"attention_mask\": input_encoding[\"attention_mask\"],\n        \"labels\": target_encoding[\"input_ids\"],\n    }\n\ntokenized_dataset = dataset.map(tokenize_content, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:20:12.733664Z","iopub.execute_input":"2025-06-25T10:20:12.733926Z","iopub.status.idle":"2025-06-25T10:20:13.276006Z","shell.execute_reply.started":"2025-06-25T10:20:12.733908Z","shell.execute_reply":"2025-06-25T10:20:13.275550Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f4379d713b4ae0b0e589182c7a7680"}},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"# 🧱 5. Setup Data Collator","metadata":{}},{"cell_type":"code","source":"# Setup Data Collator\nseq2seq_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:20:16.778405Z","iopub.execute_input":"2025-06-25T10:20:16.778916Z","iopub.status.idle":"2025-06-25T10:20:16.782208Z","shell.execute_reply.started":"2025-06-25T10:20:16.778893Z","shell.execute_reply":"2025-06-25T10:20:16.781474Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# ⚙️ 6. Define Training Arguments","metadata":{}},{"cell_type":"code","source":"# Define Training Arguments\ntraining_args = TrainingArguments(\n    output_dir=\"t5-samsum-model\",              # Where to save the model\n    num_train_epochs=1,                        # Number of training passes over data\n    per_device_train_batch_size=1,             # Samples per GPU during training\n    per_device_eval_batch_size=1,              # Samples per GPU during evaluation\n    warmup_steps=500,                          # Gradually increase LR for first 500 steps\n    weight_decay=0.01,                         # Regularization to prevent overfitting\n    logging_steps=10,                          # Log training metrics every 10 steps\n    eval_steps=500,                            # Run evaluation every 500 steps\n    save_steps=1e6,                            # Disable auto-saving during training\n    gradient_accumulation_steps=16,            # Accumulate gradients for larger batch effect\n    report_to=\"none\"                           # Disable logging to external tools\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:20:21.889857Z","iopub.execute_input":"2025-06-25T10:20:21.890146Z","iopub.status.idle":"2025-06-25T10:20:21.916395Z","shell.execute_reply.started":"2025-06-25T10:20:21.890126Z","shell.execute_reply":"2025-06-25T10:20:21.915870Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# 🏋️ 7. Initialize Trainer","metadata":{}},{"cell_type":"code","source":"# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    data_collator=seq2seq_collator,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:20:24.492529Z","iopub.execute_input":"2025-06-25T10:20:24.493301Z","iopub.status.idle":"2025-06-25T10:20:24.504661Z","shell.execute_reply.started":"2025-06-25T10:20:24.493276Z","shell.execute_reply":"2025-06-25T10:20:24.504096Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# 🚀 8. Train the Model","metadata":{}},{"cell_type":"code","source":"# Train the Model\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:20:26.559610Z","iopub.execute_input":"2025-06-25T10:20:26.559943Z","iopub.status.idle":"2025-06-25T10:39:31.706073Z","shell.execute_reply.started":"2025-06-25T10:20:26.559925Z","shell.execute_reply":"2025-06-25T10:39:31.705093Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [920/920 19:03, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>11.758500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>11.838000</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>11.841300</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>11.190400</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>10.415800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>9.748400</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>9.274000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>8.240500</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>6.700800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>5.698700</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>4.479500</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>3.292800</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>2.542200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.961200</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.709700</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.405900</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.214700</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.963800</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.853400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.774700</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.762900</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.705000</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.714700</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.652500</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.640800</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.621600</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.564500</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.585700</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.632800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.539400</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.583600</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.572800</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.525100</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.570600</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.534600</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.511600</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.495000</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.510000</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.557900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.551000</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.528100</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.520400</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.525400</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.526600</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.463900</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.496100</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.521400</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.526400</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.499000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.488200</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.522000</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.476500</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.499300</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.456800</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.494100</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.508800</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.527600</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.520900</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.455200</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.528800</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.468700</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.504000</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.546300</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.436200</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.495800</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.438900</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.528600</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.482900</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.470100</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.478500</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.463600</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.466300</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.438500</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.506300</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.468900</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.505600</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.464700</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.512400</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.450200</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.465400</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.477000</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.457200</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.492600</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.472000</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.450800</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.438000</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.503600</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.443400</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.473800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.456200</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.431900</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.497400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=920, training_loss=1.6631328080011452, metrics={'train_runtime': 1144.6114, 'train_samples_per_second': 12.871, 'train_steps_per_second': 0.804, 'total_flos': 3984462635335680.0, 'train_loss': 1.6631328080011452, 'epoch': 0.9991854466467553})"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"# 💾 9. Save Model & Tokenizer","metadata":{}},{"cell_type":"code","source":"#  Save Model & Tokenizer\nmodel.save_pretrained(\"t5_samsum_finetuned_model\")\ntokenizer.save_pretrained(\"t5_samsum_tokenizer\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:39:41.535424Z","iopub.execute_input":"2025-06-25T10:39:41.535696Z","iopub.status.idle":"2025-06-25T10:39:41.875649Z","shell.execute_reply.started":"2025-06-25T10:39:41.535675Z","shell.execute_reply":"2025-06-25T10:39:41.874790Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"('t5_samsum_tokenizer/tokenizer_config.json',\n 't5_samsum_tokenizer/special_tokens_map.json',\n 't5_samsum_tokenizer/spiece.model',\n 't5_samsum_tokenizer/added_tokens.json',\n 't5_samsum_tokenizer/tokenizer.json')"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"# 🔁 10. Reload & Setup for Inference","metadata":{}},{"cell_type":"code","source":"#  Reload & Setup for Inference\ntokenizer = AutoTokenizer.from_pretrained(\"t5_samsum_tokenizer\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"t5_samsum_finetuned_model\").to(\"cuda\")\nsummarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n# No manual tokenization, no manual model.generate() — it abstracts all that under the hood.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:39:44.595623Z","iopub.execute_input":"2025-06-25T10:39:44.596153Z","iopub.status.idle":"2025-06-25T10:39:44.818546Z","shell.execute_reply.started":"2025-06-25T10:39:44.596130Z","shell.execute_reply":"2025-06-25T10:39:44.817787Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# 🎭 11. Test Sample Dialogue (Luffy & Naruto)","metadata":{}},{"cell_type":"code","source":"# 🎭 11. Test Sample Dialogue (Luffy & Naruto)\nsample_text = '''Luffy: Naruto! You won the ramen eating contest again?! That’s your fifth win this month!\n\nNaruto: Believe it, Luffy! Ichiraku’s secret menu is my new training ground. Gotta keep up the chakra and the appetite!\n\nLuffy: Haha! I like that! I trained by eating 20 meat-on-the-bone last night. Zoro thought I was insane.\n\nNaruto: Bro, I’ve fought Akatsuki, and even I think that’s dangerous. What’s next? Competing with Goku?\n\nLuffy: Maybe! But first I wanna become the Pirate King. Then I’ll eat ramen on the moon!\n\nNaruto: You sure talk big, rubber boy. But I respect that. Becoming Hokage wasn’t easy either.\n\nLuffy: We’re kinda the same, huh? Chasing dreams, fighting crazy villains, making loyal friends.\n\nNaruto: True that. Though I don’t have a reindeer doctor or a skeleton with an afro.\n\nLuffy: And I don’t have a giant fox inside me. We’re even!\n\nNaruto: Hey, wanna team up for a mission? I heard there’s a lost treasure in the Hidden Mist village.\n\nLuffy: Treasure?! I’m in! Let’s go find it, and maybe snack along the way.\n\nNaruto: Deal. I’ll bring the kunai, you bring the appetite.\n\nLuffy: This is gonna be epic! Let's GO!!!\n\nNaruto: Dattebayo!!!'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:39:49.336864Z","iopub.execute_input":"2025-06-25T10:39:49.337454Z","iopub.status.idle":"2025-06-25T10:39:49.341163Z","shell.execute_reply.started":"2025-06-25T10:39:49.337431Z","shell.execute_reply":"2025-06-25T10:39:49.340397Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# 📄 12. Show the Summary Output","metadata":{}},{"cell_type":"code","source":"# 📄 12. Show the Summary Output\nfrom IPython.display import Markdown, display\nresult = summarizer(sample_text, max_length=100, min_length=30, do_sample=False) ## do_sampilng = False means Use greedy decoding (no randomness); always returns same result\ndisplay(Markdown(f\"**Summary:** {result[0]['summary_text']}\"))\n# result format -->> [{'summary_text': 'Here is the generated summary.'}]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T10:39:52.586035Z","iopub.execute_input":"2025-06-25T10:39:52.586352Z","iopub.status.idle":"2025-06-25T10:39:53.354236Z","shell.execute_reply.started":"2025-06-25T10:39:52.586332Z","shell.execute_reply":"2025-06-25T10:39:53.353657Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Summary:** Luffy won the ramen eating contest again this month. Luffy is training with 20 meat-on-the-bone. Naruto has fought Akatsuki, and he will compete with Goku."},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}